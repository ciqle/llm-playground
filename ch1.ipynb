{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOllama(\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    model=\"qwen2.5:32b\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-02-26T17:20:01.963705Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1020771042, 'load_duration': 25736375, 'prompt_eval_count': 36, 'prompt_eval_duration': 640000000, 'eval_count': 8, 'eval_duration': 353000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-b3887d6e-a1e5-4e6a-80ed-3edf7c52c458-0', usage_metadata={'input_tokens': 36, 'output_tokens': 8, 'total_tokens': 44})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = [HumanMessage(\"What is the capital of France?\")]\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Paris!!!', additional_kwargs={}, response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-02-26T17:20:02.463096Z', 'done': True, 'done_reason': 'stop', 'total_duration': 489998042, 'load_duration': 8184459, 'prompt_eval_count': 38, 'prompt_eval_duration': 380000000, 'eval_count': 3, 'eval_duration': 100000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-261462f2-861b-46bd-97e1-b3c243d14670-0', usage_metadata={'input_tokens': 38, 'output_tokens': 3, 'total_tokens': 41})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_msg = SystemMessage(\n",
    "    '''You are a helpful asistant that responds to questions with three \n",
    "        exclamation marks.'''\n",
    ")\n",
    "human_msg = HumanMessage('What is the capital of France?')\n",
    "\n",
    "model.invoke([system_msg, human_msg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_str = \"\"\"Answer the question based on the\n",
    "    context below. If the question cannot be answered using the information \n",
    "    provided, answer with \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate.from_template(template_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template.invoke({\n",
    "    \"context\": \"\"\"The most recent advancements in NLP are being driven by Large Language Models (LLMs). These models outperform their smaller counterparts and have become invaluable for developers who are creating applications with NLP capabilities. Developers can tap into these models through Hugging Face's `transformers` library, or by utilizing OpenAI and Cohere's offerings through the `openai` and `cohere` libraries, respectively.\"\"\",\n",
    "    \"question\": \"Which model providers offer LLMs?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The context mentions that developers can utilize Large Language Models (LLMs) from different providers. Specifically, it points out Hugging Face, OpenAI, and Cohere as offering these models through their respective libraries (`transformers` for Hugging Face, `openai`, and `cohere`). Therefore, the model providers that offer LLMs include Hugging Face, OpenAI, and Cohere.', additional_kwargs={}, response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-02-26T17:20:07.519278Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5037391750, 'load_duration': 8365292, 'prompt_eval_count': 158, 'prompt_eval_duration': 937000000, 'eval_count': 82, 'eval_duration': 4089000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-f63eff90-446b-4f3e-9a53-ff4b1e2fabd5-0', usage_metadata={'input_tokens': 158, 'output_tokens': 82, 'total_tokens': 240})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Answer the question based on the context below. If the \\n        question cannot be answered using the information provided, answer with \\n        \"I don\\'t know\".', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Context: The most recent advancements in NLP are being driven by Large \\n        Language Models (LLMs). These models outperform their smaller \\n        counterparts and have become invaluable for developers who are creating \\n        applications with NLP capabilities. Developers can tap into these \\n        models through Hugging Face's `transformers` library, or by utilizing \\n        OpenAI and Cohere's offerings through the `openai` and `cohere` \\n        libraries, respectively.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Question: Which model providers offer LLMs?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"Answer the question based on the context below. If the \n",
    "        question cannot be answered using the information provided, answer with \n",
    "        \"I don\\'t know\".\"\"\",\n",
    "        ),\n",
    "        (\"human\", \"Context: {context}\"),\n",
    "        (\"human\", \"Question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "template.invoke(\n",
    "    {\n",
    "        \"context\": \"\"\"The most recent advancements in NLP are being driven by Large \n",
    "        Language Models (LLMs). These models outperform their smaller \n",
    "        counterparts and have become invaluable for developers who are creating \n",
    "        applications with NLP capabilities. Developers can tap into these \n",
    "        models through Hugging Face's `transformers` library, or by utilizing \n",
    "        OpenAI and Cohere's offerings through the `openai` and `cohere` \n",
    "        libraries, respectively.\"\"\",\n",
    "        \"question\": \"Which model providers offer LLMs?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template.invoke(\n",
    "    {\n",
    "        \"context\": \"\"\"The most recent advancements in NLP are being driven by Large \n",
    "        Language Models (LLMs). These models outperform their smaller \n",
    "        counterparts and have become invaluable for developers who are creating \n",
    "        applications with NLP capabilities. Developers can tap into these \n",
    "        models through Hugging Face's `transformers` library, or by utilizing \n",
    "        OpenAI and Cohere's offerings through the `openai` and `cohere` \n",
    "        libraries, respectively.\"\"\",\n",
    "        \"question\": \"Which model providers offer LLMs?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The context mentions that Large Language Models (LLMs) can be accessed through Hugging Face's `transformers` library, or by utilizing OpenAI and Cohere's offerings through the `openai` and `cohere` libraries, respectively. Therefore, the model providers offering LLMs include Hugging Face, OpenAI, and Cohere.\", additional_kwargs={}, response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-02-26T17:20:12.030871Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4496209542, 'load_duration': 8131917, 'prompt_eval_count': 151, 'prompt_eval_duration': 927000000, 'eval_count': 72, 'eval_duration': 3558000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-3c887e2c-f220-493e-bcf6-cdc807e34229-0', usage_metadata={'input_tokens': 151, 'output_tokens': 72, 'total_tokens': 223})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get JSON format output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerWithJustification(BaseModel):\n",
    "    '''An answer to the user's question along with justification for the \n",
    "        answer.'''\n",
    "    answer: str\n",
    "    '''The answer to the user's question'''\n",
    "    justification: str\n",
    "    '''Justification for the answer'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_model = model.with_structured_output(AnswerWithJustification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnswerWithJustification(answer='A pound of bricks and a pound of feathers weigh the same.', justification='Both weights are specified as one pound, so regardless of the material (bricks or feathers), they both weigh exactly one pound.')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_model.invoke(\"\"\"What weighs more, a pound of bricks or a pound of feathers\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
