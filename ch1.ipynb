{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOllama(\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    model=\"qwen2.5:32b\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplest case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is Paris.', additional_kwargs={}, response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-02-26T17:20:01.963705Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1020771042, 'load_duration': 25736375, 'prompt_eval_count': 36, 'prompt_eval_duration': 640000000, 'eval_count': 8, 'eval_duration': 353000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-b3887d6e-a1e5-4e6a-80ed-3edf7c52c458-0', usage_metadata={'input_tokens': 36, 'output_tokens': 8, 'total_tokens': 44})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = [HumanMessage(\"What is the capital of France?\")]\n",
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOT FOR RUN, this is the result\n",
    "\n",
    "AIMessage(\n",
    "    content=\"The capital of France is Paris.\",\n",
    "    additional_kwargs={},\n",
    "    response_metadata={\n",
    "        \"model\": \"qwen2.5:32b\",\n",
    "        \"created_at\": \"2025-02-26T17:20:01.963705Z\",\n",
    "        \"done\": True,\n",
    "        \"done_reason\": \"stop\",\n",
    "        \"total_duration\": 1020771042,\n",
    "        \"load_duration\": 25736375,\n",
    "        \"prompt_eval_count\": 36,\n",
    "        \"prompt_eval_duration\": 640000000,\n",
    "        \"eval_count\": 8,\n",
    "        \"eval_duration\": 353000000,\n",
    "        \"message\": Message(role=\"assistant\", content=\"\", images=None, tool_calls=None),\n",
    "    },\n",
    "    id=\"run-b3887d6e-a1e5-4e6a-80ed-3edf7c52c458-0\",\n",
    "    usage_metadata={\"input_tokens\": 36, \"output_tokens\": 8, \"total_tokens\": 44},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Paris!!!', additional_kwargs={}, response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-02-26T17:20:02.463096Z', 'done': True, 'done_reason': 'stop', 'total_duration': 489998042, 'load_duration': 8184459, 'prompt_eval_count': 38, 'prompt_eval_duration': 380000000, 'eval_count': 3, 'eval_duration': 100000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-261462f2-861b-46bd-97e1-b3c243d14670-0', usage_metadata={'input_tokens': 38, 'output_tokens': 3, 'total_tokens': 41})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_msg = SystemMessage(\n",
    "    '''You are a helpful asistant that responds to questions with three exclamation marks.'''\n",
    ")\n",
    "human_msg = HumanMessage('What is the capital of France?')\n",
    "\n",
    "model.invoke([system_msg, human_msg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIMessage(\n",
    "    content=\"Paris!!!\",\n",
    "    additional_kwargs={},\n",
    "    response_metadata={\n",
    "        \"model\": \"qwen2.5:32b\",\n",
    "        \"created_at\": \"2025-02-26T17:20:02.463096Z\",\n",
    "        \"done\": True,\n",
    "        \"done_reason\": \"stop\",\n",
    "        \"total_duration\": 489998042,\n",
    "        \"load_duration\": 8184459,\n",
    "        \"prompt_eval_count\": 38,\n",
    "        \"prompt_eval_duration\": 380000000,\n",
    "        \"eval_count\": 3,\n",
    "        \"eval_duration\": 100000000,\n",
    "        \"message\": Message(role=\"assistant\", content=\"\", images=None, tool_calls=None),\n",
    "    },\n",
    "    id=\"run-261462f2-861b-46bd-97e1-b3c243d14670-0\",\n",
    "    usage_metadata={\"input_tokens\": 38, \"output_tokens\": 3, \"total_tokens\": 41},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. added template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_str = \"\"\"Answer the question based on the\n",
    "context below. If the question cannot be answered using the information \n",
    "    provided, answer with \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate.from_template(template_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template.invoke({\n",
    "    \"context\": \"\"\"The most recent advancements in NLP are being driven by Large Language Models (LLMs). These models outperform their smaller counterparts and have become invaluable for developers who are creating applications with NLP capabilities. Developers can tap into these models through Hugging Face's `transformers` library, or by utilizing OpenAI and Cohere's offerings through the `openai` and `cohere` libraries, respectively.\"\"\",\n",
    "    \"question\": \"Which model providers offer LLMs?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The context mentions that developers can utilize Large Language Models (LLMs) from different providers. Specifically, it points out Hugging Face, OpenAI, and Cohere as offering these models through their respective libraries (`transformers` for Hugging Face, `openai`, and `cohere`). Therefore, the model providers that offer LLMs include Hugging Face, OpenAI, and Cohere.', additional_kwargs={}, response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-02-26T17:20:07.519278Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5037391750, 'load_duration': 8365292, 'prompt_eval_count': 158, 'prompt_eval_duration': 937000000, 'eval_count': 82, 'eval_duration': 4089000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-f63eff90-446b-4f3e-9a53-ff4b1e2fabd5-0', usage_metadata={'input_tokens': 158, 'output_tokens': 82, 'total_tokens': 240})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOT FOR RUN!!! This is the result\n",
    "\n",
    "AIMessage(\n",
    "    content=\"The context mentions that developers can utilize Large Language Models (LLMs) from different providers. Specifically, it points out Hugging Face, OpenAI, and Cohere as offering these models through their respective libraries (`transformers` for Hugging Face, `openai`, and `cohere`). Therefore, the model providers that offer LLMs include Hugging Face, OpenAI, and Cohere.\",\n",
    "    additional_kwargs={},\n",
    "    response_metadata={\n",
    "        \"model\": \"qwen2.5:32b\",\n",
    "        \"created_at\": \"2025-02-26T17:20:07.519278Z\",\n",
    "        \"done\": True,\n",
    "        \"done_reason\": \"stop\",\n",
    "        \"total_duration\": 5037391750,\n",
    "        \"load_duration\": 8365292,\n",
    "        \"prompt_eval_count\": 158,\n",
    "        \"prompt_eval_duration\": 937000000,\n",
    "        \"eval_count\": 82,\n",
    "        \"eval_duration\": 4089000000,\n",
    "        \"message\": Message(role=\"assistant\", content=\"\", images=None, tool_calls=None),\n",
    "    },\n",
    "    id=\"run-f63eff90-446b-4f3e-9a53-ff4b1e2fabd5-0\",\n",
    "    usage_metadata={\"input_tokens\": 158, \"output_tokens\": 82, \"total_tokens\": 240},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Answer the question based on the context below. If the \\n        question cannot be answered using the information provided, answer with \\n        \"I don\\'t know\".', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Context: The most recent advancements in NLP are being driven by Large \\n        Language Models (LLMs). These models outperform their smaller \\n        counterparts and have become invaluable for developers who are creating \\n        applications with NLP capabilities. Developers can tap into these \\n        models through Hugging Face's `transformers` library, or by utilizing \\n        OpenAI and Cohere's offerings through the `openai` and `cohere` \\n        libraries, respectively.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Question: Which model providers offer LLMs?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"Answer the question based on the context below. If the \n",
    "        question cannot be answered using the information provided, answer with \n",
    "        \"I don\\'t know\".\"\"\",\n",
    "        ),\n",
    "        (\"human\", \"Context: {context}\"),\n",
    "        (\"human\", \"Question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = template.invoke(\n",
    "    {\n",
    "        \"context\": \"\"\"The most recent advancements in NLP are being driven by Large \n",
    "        Language Models (LLMs). These models outperform their smaller \n",
    "        counterparts and have become invaluable for developers who are creating \n",
    "        applications with NLP capabilities. Developers can tap into these \n",
    "        models through Hugging Face's `transformers` library, or by utilizing \n",
    "        OpenAI and Cohere's offerings through the `openai` and `cohere` \n",
    "        libraries, respectively.\"\"\",\n",
    "        \"question\": \"Which model providers offer LLMs?\",\n",
    "    }\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOT FOR RUN!!! This is the result\n",
    "\n",
    "ChatPromptValue(\n",
    "    messages=[\n",
    "        SystemMessage(\n",
    "            content='Answer the question based on the context below. If the \\n        question cannot be answered using the information provided, answer with \\n        \"I don\\'t know\".',\n",
    "            additional_kwargs={},\n",
    "            response_metadata={},\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=\"Context: The most recent advancements in NLP are being driven by Large \\n        Language Models (LLMs). These models outperform their smaller \\n        counterparts and have become invaluable for developers who are creating \\n        applications with NLP capabilities. Developers can tap into these \\n        models through Hugging Face's `transformers` library, or by utilizing \\n        OpenAI and Cohere's offerings through the `openai` and `cohere` \\n        libraries, respectively.\",\n",
    "            additional_kwargs={},\n",
    "            response_metadata={},\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=\"Question: Which model providers offer LLMs?\",\n",
    "            additional_kwargs={},\n",
    "            response_metadata={},\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The context mentions that Large Language Models (LLMs) can be accessed through Hugging Face's `transformers` library, or by utilizing OpenAI and Cohere's offerings through the `openai` and `cohere` libraries, respectively. Therefore, the model providers offering LLMs include Hugging Face, OpenAI, and Cohere.\", additional_kwargs={}, response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-02-26T17:20:12.030871Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4496209542, 'load_duration': 8131917, 'prompt_eval_count': 151, 'prompt_eval_duration': 927000000, 'eval_count': 72, 'eval_duration': 3558000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-3c887e2c-f220-493e-bcf6-cdc807e34229-0', usage_metadata={'input_tokens': 151, 'output_tokens': 72, 'total_tokens': 223})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOT FOR RUN!!! This is the result\n",
    "\n",
    "AIMessage(\n",
    "    content=\"The context mentions that Large Language Models (LLMs) can be accessed through Hugging Face's `transformers` library, or by utilizing OpenAI and Cohere's offerings through the `openai` and `cohere` libraries, respectively. Therefore, the model providers offering LLMs include Hugging Face, OpenAI, and Cohere.\",\n",
    "    additional_kwargs={},\n",
    "    response_metadata={\n",
    "        \"model\": \"qwen2.5:32b\",\n",
    "        \"created_at\": \"2025-02-26T17:20:12.030871Z\",\n",
    "        \"done\": True,\n",
    "        \"done_reason\": \"stop\",\n",
    "        \"total_duration\": 4496209542,\n",
    "        \"load_duration\": 8131917,\n",
    "        \"prompt_eval_count\": 151,\n",
    "        \"prompt_eval_duration\": 927000000,\n",
    "        \"eval_count\": 72,\n",
    "        \"eval_duration\": 3558000000,\n",
    "        \"message\": Message(role=\"assistant\", content=\"\", images=None, tool_calls=None),\n",
    "    },\n",
    "    id=\"run-3c887e2c-f220-493e-bcf6-cdc807e34229-0\",\n",
    "    usage_metadata={\"input_tokens\": 151, \"output_tokens\": 72, \"total_tokens\": 223},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get JSON format output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerWithJustification(BaseModel):\n",
    "    '''An answer to the user's question along with justification for the answer.'''\n",
    "    \n",
    "    answer: str\n",
    "    '''The answer to the user's question'''\n",
    "    \n",
    "    justification: str\n",
    "    '''Justification for the answer'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_model = model.with_structured_output(AnswerWithJustification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnswerWithJustification(answer='A pound of bricks and a pound of feathers weigh the same.', justification='Both weights are specified as one pound, so regardless of the material (bricks or feathers), they both weigh exactly one pound.')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_model.invoke(\"\"\"What weighs more, a pound of bricks or a pound of feathers\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOT FOR RUN!!! This is the result\n",
    "\n",
    "AnswerWithJustification(\n",
    "    answer=\"A pound of bricks and a pound of feathers weigh the same.\",\n",
    "    justification=\"Both weights are specified as one pound, so regardless of the material (bricks or feathers), they both weigh exactly one pound.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "items = parser.invoke(\"apple, banana, cherry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'banana', 'cherry']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today? Feel free to ask any questions or let me know if you need help with anything specific.', additional_kwargs={}, response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-02-27T17:04:09.318712Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2690814542, 'load_duration': 554773667, 'prompt_eval_count': 32, 'prompt_eval_duration': 626000000, 'eval_count': 28, 'eval_duration': 1338000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-f21b2156-f8dc-47d0-9d0a-23979f912eaa-0', usage_metadata={'input_tokens': 32, 'output_tokens': 28, 'total_tokens': 60})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion = model.invoke('Hi there!') \n",
    "# Hi!\n",
    "\n",
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hello! How can I assist you today? Feel free to ask any questions or let me know if you need help with anything specific.', additional_kwargs={}, response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-02-27T17:04:17.136108Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2833488792, 'load_duration': 29078917, 'prompt_eval_count': 32, 'prompt_eval_duration': 755000000, 'eval_count': 28, 'eval_duration': 2047000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-1748199b-e650-4e9f-b2e6-e0dc7800df73-0', usage_metadata={'input_tokens': 32, 'output_tokens': 28, 'total_tokens': 60}),\n",
       " AIMessage(content='Goodbye! If you have more questions in the future, feel free to reach out. Have a great day!', additional_kwargs={}, response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-02-27T17:04:16.936169Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2633058416, 'load_duration': 28697541, 'prompt_eval_count': 32, 'prompt_eval_duration': 755000000, 'eval_count': 24, 'eval_duration': 1846000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-b8eb035c-0acb-43d7-8369-0ac8ef336408-0', usage_metadata={'input_tokens': 32, 'output_tokens': 24, 'total_tokens': 56})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 同时向语言模型发送多个提示（prompts）并获取对应的回复\n",
    "\n",
    "completions = model.batch(['Hi there!', 'Bye!'])\n",
    "# ['Hi!', 'See you!']\n",
    "\n",
    "# 对这两个提示的响应，通常是一个包含两个回复的list\n",
    "completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### NOT FOR RUN!!! This is the result\n",
    "\n",
    "[\n",
    "    AIMessage(\n",
    "        content=\"Hello! How can I assist you today? Feel free to ask any questions or let me know if you need help with anything specific.\",\n",
    "        additional_kwargs={},\n",
    "        response_metadata={\n",
    "            \"model\": \"qwen2.5:32b\",\n",
    "            \"created_at\": \"2025-02-27T17:04:17.136108Z\",\n",
    "            \"done\": True,\n",
    "            \"done_reason\": \"stop\",\n",
    "            \"total_duration\": 2833488792,\n",
    "            \"load_duration\": 29078917,\n",
    "            \"prompt_eval_count\": 32,\n",
    "            \"prompt_eval_duration\": 755000000,\n",
    "            \"eval_count\": 28,\n",
    "            \"eval_duration\": 2047000000,\n",
    "            \"message\": Message(\n",
    "                role=\"assistant\", content=\"\", images=None, tool_calls=None\n",
    "            ),\n",
    "        },\n",
    "        id=\"run-1748199b-e650-4e9f-b2e6-e0dc7800df73-0\",\n",
    "        usage_metadata={\"input_tokens\": 32, \"output_tokens\": 28, \"total_tokens\": 60},\n",
    "    ),\n",
    "    AIMessage(\n",
    "        content=\"Goodbye! If you have more questions in the future, feel free to reach out. Have a great day!\",\n",
    "        additional_kwargs={},\n",
    "        response_metadata={\n",
    "            \"model\": \"qwen2.5:32b\",\n",
    "            \"created_at\": \"2025-02-27T17:04:16.936169Z\",\n",
    "            \"done\": True,\n",
    "            \"done_reason\": \"stop\",\n",
    "            \"total_duration\": 2633058416,\n",
    "            \"load_duration\": 28697541,\n",
    "            \"prompt_eval_count\": 32,\n",
    "            \"prompt_eval_duration\": 755000000,\n",
    "            \"eval_count\": 24,\n",
    "            \"eval_duration\": 1846000000,\n",
    "            \"message\": Message(\n",
    "                role=\"assistant\", content=\"\", images=None, tool_calls=None\n",
    "            ),\n",
    "        },\n",
    "        id=\"run-b8eb035c-0acb-43d7-8369-0ac8ef336408-0\",\n",
    "        usage_metadata={\"input_tokens\": 32, \"output_tokens\": 24, \"total_tokens\": 56},\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Good' additional_kwargs={} response_metadata={} id='run-daeb65c8-23e9-4d39-88fd-26c0c5ddbcee'\n",
      "content='bye' additional_kwargs={} response_metadata={} id='run-daeb65c8-23e9-4d39-88fd-26c0c5ddbcee'\n",
      "content='!' additional_kwargs={} response_metadata={} id='run-daeb65c8-23e9-4d39-88fd-26c0c5ddbcee'\n",
      "content=' If' additional_kwargs={} response_metadata={} id='run-daeb65c8-23e9-4d39-88fd-26c0c5ddbcee'\n",
      "content=' you' additional_kwargs={} response_metadata={} id='run-daeb65c8-23e9-4d39-88fd-26c0c5ddbcee'\n",
      "content=' have' additional_kwargs={} response_metadata={} id='run-daeb65c8-23e9-4d39-88fd-26c0c5ddbcee'\n",
      "content=' more' additional_kwargs={} response_metadata={} id='run-daeb65c8-23e9-4d39-88fd-26c0c5ddbcee'\n",
      "content=' questions' additional_kwargs={} response_metadata={} id='run-daeb65c8-23e9-4d39-88fd-26c0c5ddbcee'\n",
      "content=' in' additional_kwargs={} response_metadata={} id='run-daeb65c8-23e9-4d39-88fd-26c0c5ddbcee'\n",
      "content=' the' additional_kwargs={} response_metadata={} id='run-daeb65c8-23e9-4d39-88fd-26c0c5ddbcee'\n",
      "content=' future' additional_kwargs={} response_metadata={} id='run-daeb65c8-23e9-4d39-88fd-26c0c5ddbcee'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run-daeb65c8-23e9-4d39-88fd-26c0c5ddbcee'\n",
      "content=' feel' additional_kwargs={} response_metadata={} id='run-daeb65c8-23e9-4d39-88fd-26c0c5ddbcee'\n",
      "content=' free' additional_kwargs={} response_metadata={} id='run-daeb65c8-23e9-4d39-88fd-26c0c5ddbcee'\n",
      "content=' to' additional_kwargs={} response_metadata={} id='run-daeb65c8-23e9-4d39-88fd-26c0c5ddbcee'\n",
      "content=' ask' additional_kwargs={} response_metadata={} id='run-daeb65c8-23e9-4d39-88fd-26c0c5ddbcee'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run-daeb65c8-23e9-4d39-88fd-26c0c5ddbcee'\n",
      "content=' Have' additional_kwargs={} response_metadata={} id='run-daeb65c8-23e9-4d39-88fd-26c0c5ddbcee'\n",
      "content=' a' additional_kwargs={} response_metadata={} id='run-daeb65c8-23e9-4d39-88fd-26c0c5ddbcee'\n",
      "content=' great' additional_kwargs={} response_metadata={} id='run-daeb65c8-23e9-4d39-88fd-26c0c5ddbcee'\n",
      "content=' day' additional_kwargs={} response_metadata={} id='run-daeb65c8-23e9-4d39-88fd-26c0c5ddbcee'\n",
      "content='!' additional_kwargs={} response_metadata={} id='run-daeb65c8-23e9-4d39-88fd-26c0c5ddbcee'\n",
      "content='' additional_kwargs={} response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-02-27T17:04:20.445855Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1597491708, 'load_duration': 27478333, 'prompt_eval_count': 32, 'prompt_eval_duration': 471000000, 'eval_count': 23, 'eval_duration': 1096000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-daeb65c8-23e9-4d39-88fd-26c0c5ddbcee' usage_metadata={'input_tokens': 32, 'output_tokens': 23, 'total_tokens': 55}\n"
     ]
    }
   ],
   "source": [
    "for token in model.stream('Bye!'):\n",
    "    print(token)\n",
    "    # Good\n",
    "    # bye\n",
    "    # !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imperative Composition 命令式组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the building blocks\n",
    "\n",
    "# 这里是把系统消息和用户消息组合在一起的模板\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'You are a helpful assistant.'),\n",
    "    ('human', '{question}'),\n",
    "])\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### NOT FOR RUN!!! This is the result\n",
    "\n",
    "ChatPromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    input_types={},\n",
    "    partial_variables={},\n",
    "    messages=[\n",
    "        SystemMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=[],\n",
    "                input_types={},\n",
    "                partial_variables={},\n",
    "                template=\"You are a helpful assistant.\",\n",
    "            ),\n",
    "            additional_kwargs={},\n",
    "        ),\n",
    "        HumanMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=[\"question\"],\n",
    "                input_types={},\n",
    "                partial_variables={},\n",
    "                template=\"{question}\",\n",
    "            ),\n",
    "            additional_kwargs={},\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine them in a function\n",
    "# @chain decorator adds the same Runnable interface for any function you write\n",
    "# @chain装饰器为你编写的任何函数添加了相同的Runnable接口\n",
    "\n",
    "# chatbot所做的事情就是先把values填充到template里，然后再把填充后的template传给model\n",
    "@chain\n",
    "def chatbot(values):\n",
    "    prompt = template.invoke(values)\n",
    "    return model.invoke(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Several model providers offer Large Language Models (LLMs). Here are some of the notable ones:\\n\\n1. **OpenAI**: Known for models like GPT-3, GPT-4, and ChatGPT.\\n2. **Anthropic**: Offers Claude, a large language model.\\n3. **Google AI**: Provides models such as PaLM and LaMDA.\\n4. **Hugging Face**: Hosts a wide variety of LLMs contributed by researchers and developers worldwide, including versions of BLOOM, T5, and others.\\n5. **AliCloud (M6)**: Offers the M6 model which is a multimodal pretrained foundation model.\\n6. **Microsoft Azure AI**: Provides models like Turing NLG and partnerships with OpenAI.\\n7. **Nvidia**: While not primarily a provider of LLMs, they offer tools for training large language models using frameworks such as Megatron-LM.\\n8. **Cohere**: Offers models like Command and Generate.\\n9. **EleutherAI**: Known for models such as GPT-Neo and Pythia.\\n\\nThese providers offer different features and capabilities depending on the specific model, so it's worth exploring each one to find the best fit for your needs.\", additional_kwargs={}, response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-02-27T17:16:43.482748Z', 'done': True, 'done_reason': 'stop', 'total_duration': 13990853334, 'load_duration': 564961000, 'prompt_eval_count': 27, 'prompt_eval_duration': 625000000, 'eval_count': 252, 'eval_duration': 12619000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-0a750a3c-909f-4c3e-806e-a0de33876a77-0', usage_metadata={'input_tokens': 27, 'output_tokens': 252, 'total_tokens': 279})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use it\n",
    "\n",
    "chatbot.invoke({\"question\": \"Which model providers offer LLMs?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enable stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 区别于上个版本的chatbot，这里调用的是model.stream，而不是model.invoke\n",
    "# 这样可以逐个返回模型的输出，而不是等到模型完成所有计算后再返回\n",
    "# yield的作用是把函数变成一个生成器，这样可以逐个返回模型的输出\n",
    "\n",
    "@chain\n",
    "def chatbot(values):\n",
    "    prompt = template.invoke(values)\n",
    "    for token in model.stream(prompt):\n",
    "        yield token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Several' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' companies' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' organizations' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' provide' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Large' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Language' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Models' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' (' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='LL' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='Ms' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=').' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Here' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' are' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' some' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' notable' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' ones' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=':\\n\\n' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='1' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='Open' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='AI' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Known' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' for' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' creating' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' like' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' G' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='PT' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='-' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='3' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' G' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='PT' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='-' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='4' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' other' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' advanced' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' language' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='.\\n' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='2' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='Anth' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='ropic' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Providers' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Claude' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' which' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' is' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' a' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' competitive' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' alternative' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' to' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Open' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='AI' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='’s' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='.\\n' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='3' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='Google' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Offers' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Pa' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='LM' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' (' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='Path' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='ways' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Language' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Model' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=')' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' La' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='MD' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='A' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' (' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='Language' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Models' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' for' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Dialogue' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Applications' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=').\\n' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='4' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='Meta' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' (' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='formerly' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Facebook' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=')**' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=':' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Known' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' for' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' L' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='La' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='MA' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' (' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='Large' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Language' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Model' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Meta' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' AI' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=')' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' other' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' research' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='-based' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='.\\n' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='5' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='Al' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='ibaba' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Cloud' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Offers' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Q' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='wen' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' a' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' family' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' large' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' language' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='.\\n' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='6' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='N' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='VIDIA' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Provides' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Ne' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='Mo' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' a' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' framework' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' that' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' includes' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' pre' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='-trained' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' large' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' language' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='.\\n' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='7' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='C' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='oh' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='ere' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Offers' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' various' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' language' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' designed' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' for' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' specific' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' tasks' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' like' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' text' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' generation' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' classification' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' more' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='.\\n' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='8' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='H' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='ugging' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' Face' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' A' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' platform' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' that' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' hosts' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' many' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' open' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='-source' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' L' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='LM' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='s' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' contributed' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' by' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' researchers' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' worldwide' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' including' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' from' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' other' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' providers' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='.\\n\\n' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='These' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' are' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' some' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' the' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' major' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' players' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' in' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' the' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' field' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' large' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' language' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' each' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' with' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' their' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' own' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' unique' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' offerings' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content=' capabilities' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4'\n",
      "content='' additional_kwargs={} response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-02-27T17:18:53.659145Z', 'done': True, 'done_reason': 'stop', 'total_duration': 11980650208, 'load_duration': 24830292, 'prompt_eval_count': 27, 'prompt_eval_duration': 402000000, 'eval_count': 233, 'eval_duration': 11552000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-a791f761-c107-4d4c-b9ea-8864acc044a4' usage_metadata={'input_tokens': 27, 'output_tokens': 233, 'total_tokens': 260}\n"
     ]
    }
   ],
   "source": [
    "for part in chatbot.stream({\n",
    "    \"question\": \"Which model providers offer LLMs?\"\n",
    "}):\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For asynchronous execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "async def chatbot(values):\n",
    "    prompt = await template.ainvoke(values)\n",
    "    return await model.ainvoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Several companies and organizations provide access to Large Language Models (LLMs). Here is a list of some prominent ones:\\n\\n1. **OpenAI** - Known for models like GPT-3, GPT-4, and others.\\n2. **Anthropic** - Offers Claude, which competes with OpenAI's models.\\n3. **Google** - Provides PaLM (Pathways Language Model) and related variants through their AI services.\\n4. **Meta (formerly Facebook)** - Has developed LLaMA (Large Language Model Meta AI).\\n5. **NVIDIA** - Known for NeMo, which includes a suite of language models.\\n6. **Hugging Face** - Offers a wide variety of LLMs and provides tools to work with them, including their own models like BLOOM and Dolly.\\n7. **Cohere** - Provides models like Command and other variants through their API.\\n8. **阿里云 (Alibaba Cloud)** - Develops and offers models such as Qwen.\\n9. **百度 (Baidu)** - Has developed ERNIE models.\\n10. **腾讯 (Tencent)** - Offers models like Q-Seq.\\n\\nThese providers offer different capabilities, pricing structures, and access methods, so it's important to evaluate which one best fits your needs based on factors such as performance requirements, budget, and specific use cases.\", additional_kwargs={}, response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-02-27T17:25:23.344885Z', 'done': True, 'done_reason': 'stop', 'total_duration': 15369292375, 'load_duration': 561442208, 'prompt_eval_count': 27, 'prompt_eval_duration': 626000000, 'eval_count': 280, 'eval_duration': 14003000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-b98f572c-f819-4c61-aade-32bfee648ee4-0', usage_metadata={'input_tokens': 27, 'output_tokens': 280, 'total_tokens': 307})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chatbot.ainvoke({\"question\": \"Which model providers offer LLMs?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LCEL is a *declarative language* for composing LangChain components. LangChain compiles LCEL compositions to an *optimized execution plan*, with automatic parallelization, streaming, tracing, and async support.\n",
    "\n",
    "LCEL是一种用于组合LangChain组件的声明式语言。LangChain将LCEL组合编译为一个优化的执行计划，支持自动并行化、流处理、追踪和异步操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Several companies and organizations provide Large Language Models (LLMs). Here is a list of some prominent ones:\\n\\n1. **Anthropic** - Known for models like Claude.\\n2. **AI21 Labs** - Offers models such as Jurassic-2.\\n3. **阿里云** - Provides Qwen, which is their large language model.\\n4. **Aleph Alpha** - Known for the AlephAlpha models.\\n5. **Anyscale (Anthropic)** - Developed the Claude series of LLMs.\\n6. **Cohere** - Offers models like Command and Command-Instant.\\n7. **Google** - Provides PaLM, LaMDA, and Pathways Language Model.\\n8. **MosaicML** - Known for models such as MPT (Mosaic Foundation Tuned).\\n9. **NVIDIA** - Works on various language model projects, including NeMo.\\n10. **OpenAI** - Famous for models like GPT-3, GPT-4, and the older versions of GPT.\\n11. **Stability AI** - Known for StableLM.\\n12. **Microsoft** - Offers Azure AI services which include their own large language model offerings.\\n13. **Meta (formerly Facebook)** - Has models like LLaMA.\\n\\nThese providers often offer different capabilities and use cases, so the choice of a specific provider might depend on your particular needs and requirements.', additional_kwargs={}, response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-02-27T17:26:32.820071Z', 'done': True, 'done_reason': 'stop', 'total_duration': 14923534708, 'load_duration': 29994708, 'prompt_eval_count': 27, 'prompt_eval_duration': 432000000, 'eval_count': 289, 'eval_duration': 14460000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-a53a8b64-021b-4e3d-bd95-5af570e085ec-0', usage_metadata={'input_tokens': 27, 'output_tokens': 289, 'total_tokens': 316})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the building blocks\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'You are a helpful assistant.'),\n",
    "    ('human', '{question}'),\n",
    "])\n",
    "\n",
    "# combine them with the | operator\n",
    "\n",
    "chatbot = template | model\n",
    "\n",
    "# use it\n",
    "\n",
    "chatbot.invoke({\"question\": \"Which model providers offer LLMs?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Several' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' companies' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' organizations' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' provide' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' Large' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' Language' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' Models' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' (' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='LL' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='Ms' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=').' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' Here' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' is' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' a' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' list' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' some' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' prominent' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' ones' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=':\\n\\n' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='1' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='Open' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='AI' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' Known' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' for' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' like' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' G' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='PT' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='-' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='3' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' G' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='PT' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='-' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='4' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' others' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='.\\n' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='2' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='Anth' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='ropic' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' Creator' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' the' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' Claude' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' series' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' of' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' language' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='.\\n' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='3' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='Google' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' Offers' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' Pa' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='LM' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' (' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='Path' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='ways' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' Language' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' Model' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=')' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' and' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' its' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' successors' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='.\\n' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='4' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='Meta' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' (' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='Facebook' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=')**' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=':' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' Developed' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' L' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='La' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='MA' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' (' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='Large' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' Language' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' Model' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' Meta' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' AI' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=').\\n' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='5' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='N' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='VIDIA' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' Provides' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' Ne' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='Mo' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=',' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' a' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' framework' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' that' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' includes' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' large' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' language' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' models' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='.\\n' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='6' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='Microsoft' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' Collabor' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='ates' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' with' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' Open' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='AI' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' to' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' offer' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' Azure' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' AI' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' services' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='.\\n' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='7' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='阿里' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='云' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='（' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='Ali' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='yun' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='）' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' 提' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='供' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='通' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='义' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='千' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='问' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='等' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='大型' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='语言' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='模型' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='。\\n' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='8' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='百度' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='（' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='B' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='aidu' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='）' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' 开' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='发' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='了' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='文' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='心' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='一' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='言' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='等' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='语言' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='模型' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='。\\n' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='9' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='.' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' **' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='京东' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='（' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='JD' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='.com' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='）' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='**:' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content=' 其' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='研究' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='部门' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='也' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='开发' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='了自己的' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='大型' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='语言' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='模型' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='。\\n\\n' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='这些' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='供应商' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='提供了' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='各种' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='各' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='样的' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='大' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='语言' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='模型' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='，' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='适用于' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='不同的' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='应用场景' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='和' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='需求' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='。' additional_kwargs={} response_metadata={} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0'\n",
      "content='' additional_kwargs={} response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-02-27T17:27:22.260294Z', 'done': True, 'done_reason': 'stop', 'total_duration': 10739896000, 'load_duration': 24952000, 'prompt_eval_count': 27, 'prompt_eval_duration': 414000000, 'eval_count': 208, 'eval_duration': 10298000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)} id='run-2c7ec703-10a9-49c3-a0b3-20fea070f8f0' usage_metadata={'input_tokens': 27, 'output_tokens': 208, 'total_tokens': 235}\n"
     ]
    }
   ],
   "source": [
    "for part in chatbot.stream({\n",
    "    \"question\": \"Which model providers offer LLMs?\"\n",
    "}):\n",
    "    print(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Several model providers offer Large Language Models (LLMs). Here is a list of some notable ones:\\n\\n1. **Anthropic**: Known for models like Claude.\\n2. **AI21 Labs**: Offers the Jurassic-2 series.\\n3. **Alibaba Cloud**: Provides the Qwen series.\\n4. **Aleph Alpha**: Offers models like AlephAlpha.\\n5. **Anthropic (Claude)**: Known for their AI assistant Claude.\\n6. **阿里云（Qwen）**: Alibaba Cloud's Qwen series.\\n7. **百度（文心一言）**: Baidu’s Wenxin Yiyan model.\\n8. **ByteDance (Baichuan)**: Offers the Baichuan series.\\n9. **Cohere**: Known for models like Command and Generate.\\n10. **EleutherAI**: Open-source models such as GPT-NeoX.\\n11. **Hugging Face**: Provides a variety of models through their platform, including ones from other providers.\\n12. **Junnan LIU (Qwen)**: Qwen series models provided by Junnan Liu.\\n13. **Laion**: Offers open-source models like LLMs trained on the LAION dataset.\\n14. **MistralAI**: Known for the Mistral model.\\n15. **Nvidia**: Provides tools and frameworks to train large language models, including their own custom models.\\n16. **OpenAssistant**: An open-source project that provides large language models.\\n17. **Salesforce (CodeGen)**: Offers CodeGen for code generation tasks.\\n18. **Stability AI (StableLM)**: Known for StableLM.\\n19. **Tongyi (Qwen)**: Qwen series from Tong Yi company.\\n20. **Yandex**: Provides Yandex.LM.\\n\\nThis list is not exhaustive, and new models and providers are continually emerging in the rapidly evolving field of AI language modeling.\", additional_kwargs={}, response_metadata={'model': 'qwen2.5:32b', 'created_at': '2025-02-27T17:27:42.594528Z', 'done': True, 'done_reason': 'stop', 'total_duration': 20327006333, 'load_duration': 8537083, 'prompt_eval_count': 27, 'prompt_eval_duration': 49000000, 'eval_count': 400, 'eval_duration': 20268000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-abd649db-f75b-4039-80a5-fa892bf01c7a-0', usage_metadata={'input_tokens': 27, 'output_tokens': 400, 'total_tokens': 427})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chatbot.ainvoke({\n",
    "    \"question\": \"Which model providers offer LLMs?\"\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
